{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reddit Classification Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import timeit\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# increase columns shown to see all columns \n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reddit = pd.read_csv('./reddit_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adserver_click_url</th>\n",
       "      <th>adserver_imp_pixel</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>contest_mode</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>disable_comments</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>domain</th>\n",
       "      <th>downs</th>\n",
       "      <th>edited</th>\n",
       "      <th>gilded</th>\n",
       "      <th>hide_score</th>\n",
       "      <th>href_url</th>\n",
       "      <th>id</th>\n",
       "      <th>imp_pixel</th>\n",
       "      <th>is_self</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>locked</th>\n",
       "      <th>media</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>mobile_ad_url</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>original_link</th>\n",
       "      <th>over_18</th>\n",
       "      <th>permalink</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>preview</th>\n",
       "      <th>promoted</th>\n",
       "      <th>promoted_by</th>\n",
       "      <th>promoted_display_name</th>\n",
       "      <th>promoted_url</th>\n",
       "      <th>quarantine</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>saved</th>\n",
       "      <th>score</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>secure_media_embed</th>\n",
       "      <th>selftext</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>third_party_tracking</th>\n",
       "      <th>third_party_tracking_2</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>johnnyawesome0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1480697304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self.techsupport</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5g49s2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_5g49s2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/techsupport/comments/5g49s2/help_with_audio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.484297e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>I have a Sony surround sound system for a blu-...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>techsupport</td>\n",
       "      <td>t5_2qioo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self</td>\n",
       "      <td>Help with audio set-up</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/techsupport/comments/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Silverfin113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1480697424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self.learnprogramming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5g4a5p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_5g4a5p</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/learnprogramming/comments/5g4a5p/optimizing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.484297e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>I've written what seems to be a prohibitively ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>learnprogramming</td>\n",
       "      <td>t5_2r7yd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self</td>\n",
       "      <td>Optimizing code for speed</td>\n",
       "      <td>23.0</td>\n",
       "      <td>https://www.reddit.com/r/learnprogramming/comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>bookbooksbooks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1480697613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self.gamedev</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5g4att</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>discussion cat-talk</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_5g4att</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/gamedev/comments/5g4att/seeking_tales_of_de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.484297e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>I'm writing an article called \"Video Games Tha...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gamedev</td>\n",
       "      <td>t5_2qi0a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self</td>\n",
       "      <td>Seeking Tales of Development Woe (and Triumph)...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>https://www.reddit.com/r/gamedev/comments/5g4a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1480697634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self.learnprogramming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1480698462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5g4awr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>solved</td>\n",
       "      <td>Solved</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_5g4awr</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/learnprogramming/comments/5g4awr/java_findi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.484297e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>learnprogramming</td>\n",
       "      <td>t5_2r7yd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>default</td>\n",
       "      <td>[Java] Finding smallest value in an array</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.reddit.com/r/learnprogramming/comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>caffeine_potent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1480697748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self.learnpython</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1480709138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5g4bcr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_5g4bcr</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/learnpython/comments/5g4bcr/currying_functi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.484297e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{}</td>\n",
       "      <td>I have the following representation of argumen...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>learnpython</td>\n",
       "      <td>t5_2r8ot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self</td>\n",
       "      <td>currying functions using functools</td>\n",
       "      <td>6.0</td>\n",
       "      <td>https://www.reddit.com/r/learnpython/comments/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adserver_click_url  adserver_imp_pixel  archived           author  \\\n",
       "0                 NaN                 NaN     False   johnnyawesome0   \n",
       "1                 NaN                 NaN     False     Silverfin113   \n",
       "2                 NaN                 NaN     False   bookbooksbooks   \n",
       "3                 NaN                 NaN     False        [deleted]   \n",
       "4                 NaN                 NaN     False  caffeine_potent   \n",
       "\n",
       "  author_flair_css_class author_flair_text  contest_mode  created_utc  \\\n",
       "0                    NaN               NaN         False   1480697304   \n",
       "1                    NaN               NaN         False   1480697424   \n",
       "2                    NaN               NaN         False   1480697613   \n",
       "3                    NaN               NaN         False   1480697634   \n",
       "4                    NaN               NaN         False   1480697748   \n",
       "\n",
       "   disable_comments distinguished                 domain  downs      edited  \\\n",
       "0               NaN           NaN       self.techsupport    0.0       False   \n",
       "1               NaN           NaN  self.learnprogramming    0.0       False   \n",
       "2               NaN           NaN           self.gamedev    0.0       False   \n",
       "3               NaN           NaN  self.learnprogramming    0.0  1480698462   \n",
       "4               NaN           NaN       self.learnpython    0.0  1480709138   \n",
       "\n",
       "   gilded  hide_score  href_url      id  imp_pixel  is_self  \\\n",
       "0     0.0       False       NaN  5g49s2        NaN     True   \n",
       "1     0.0       False       NaN  5g4a5p        NaN     True   \n",
       "2     0.0       False       NaN  5g4att        NaN     True   \n",
       "3     0.0       False       NaN  5g4awr        NaN     True   \n",
       "4     0.0       False       NaN  5g4bcr        NaN     True   \n",
       "\n",
       "  link_flair_css_class link_flair_text  locked media media_embed  \\\n",
       "0                  NaN             NaN   False   NaN          {}   \n",
       "1                  NaN             NaN   False   NaN          {}   \n",
       "2  discussion cat-talk      Discussion   False   NaN          {}   \n",
       "3               solved          Solved   False   NaN          {}   \n",
       "4                  NaN             NaN   False   NaN          {}   \n",
       "\n",
       "   mobile_ad_url       name  num_comments  original_link  over_18  \\\n",
       "0            NaN  t3_5g49s2           1.0            NaN    False   \n",
       "1            NaN  t3_5g4a5p           8.0            NaN    False   \n",
       "2            NaN  t3_5g4att           5.0            NaN    False   \n",
       "3            NaN  t3_5g4awr           9.0            NaN    False   \n",
       "4            NaN  t3_5g4bcr          12.0            NaN    False   \n",
       "\n",
       "                                           permalink post_hint preview  \\\n",
       "0  /r/techsupport/comments/5g49s2/help_with_audio...       NaN     NaN   \n",
       "1  /r/learnprogramming/comments/5g4a5p/optimizing...       NaN     NaN   \n",
       "2  /r/gamedev/comments/5g4att/seeking_tales_of_de...       NaN     NaN   \n",
       "3  /r/learnprogramming/comments/5g4awr/java_findi...       NaN     NaN   \n",
       "4  /r/learnpython/comments/5g4bcr/currying_functi...       NaN     NaN   \n",
       "\n",
       "   promoted  promoted_by  promoted_display_name  promoted_url  quarantine  \\\n",
       "0       NaN          NaN                    NaN           NaN       False   \n",
       "1       NaN          NaN                    NaN           NaN       False   \n",
       "2       NaN          NaN                    NaN           NaN       False   \n",
       "3       NaN          NaN                    NaN           NaN       False   \n",
       "4       NaN          NaN                    NaN           NaN       False   \n",
       "\n",
       "   retrieved_on  saved  score secure_media secure_media_embed  \\\n",
       "0  1.484297e+09  False    1.0          NaN                 {}   \n",
       "1  1.484297e+09  False   23.0          NaN                 {}   \n",
       "2  1.484297e+09  False   12.0          NaN                 {}   \n",
       "3  1.484297e+09  False    0.0          NaN                 {}   \n",
       "4  1.484297e+09  False    6.0          NaN                 {}   \n",
       "\n",
       "                                            selftext  spoiler  stickied  \\\n",
       "0  I have a Sony surround sound system for a blu-...    False     False   \n",
       "1  I've written what seems to be a prohibitively ...    False     False   \n",
       "2  I'm writing an article called \"Video Games Tha...    False     False   \n",
       "3                                          [deleted]    False     False   \n",
       "4  I have the following representation of argumen...    False     False   \n",
       "\n",
       "          subreddit subreddit_id  third_party_tracking  \\\n",
       "0       techsupport     t5_2qioo                   NaN   \n",
       "1  learnprogramming     t5_2r7yd                   NaN   \n",
       "2           gamedev     t5_2qi0a                   NaN   \n",
       "3  learnprogramming     t5_2r7yd                   NaN   \n",
       "4       learnpython     t5_2r8ot                   NaN   \n",
       "\n",
       "   third_party_tracking_2 thumbnail  \\\n",
       "0                     NaN      self   \n",
       "1                     NaN      self   \n",
       "2                     NaN      self   \n",
       "3                     NaN   default   \n",
       "4                     NaN      self   \n",
       "\n",
       "                                               title   ups  \\\n",
       "0                             Help with audio set-up   1.0   \n",
       "1                          Optimizing code for speed  23.0   \n",
       "2  Seeking Tales of Development Woe (and Triumph)...  12.0   \n",
       "3          [Java] Finding smallest value in an array   0.0   \n",
       "4                 currying functions using functools   6.0   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.reddit.com/r/techsupport/comments/...  \n",
       "1  https://www.reddit.com/r/learnprogramming/comm...  \n",
       "2  https://www.reddit.com/r/gamedev/comments/5g4a...  \n",
       "3  https://www.reddit.com/r/learnprogramming/comm...  \n",
       "4  https://www.reddit.com/r/learnpython/comments/...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26688, 53)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to include\n",
    "\n",
    "Many of the columns included in this data set have many null values or have little varition. The following section picks out the featues that can be usesful to a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26688 entries, 0 to 26687\n",
      "Data columns (total 53 columns):\n",
      "adserver_click_url        0 non-null float64\n",
      "adserver_imp_pixel        0 non-null float64\n",
      "archived                  26688 non-null bool\n",
      "author                    26688 non-null object\n",
      "author_flair_css_class    435 non-null object\n",
      "author_flair_text         351 non-null object\n",
      "contest_mode              26688 non-null bool\n",
      "created_utc               26688 non-null int64\n",
      "disable_comments          0 non-null float64\n",
      "distinguished             85 non-null object\n",
      "domain                    26688 non-null object\n",
      "downs                     26688 non-null float64\n",
      "edited                    26688 non-null object\n",
      "gilded                    26688 non-null float64\n",
      "hide_score                26688 non-null bool\n",
      "href_url                  0 non-null float64\n",
      "id                        26688 non-null object\n",
      "imp_pixel                 0 non-null float64\n",
      "is_self                   26688 non-null bool\n",
      "link_flair_css_class      4292 non-null object\n",
      "link_flair_text           4610 non-null object\n",
      "locked                    26688 non-null bool\n",
      "media                     268 non-null object\n",
      "media_embed               26688 non-null object\n",
      "mobile_ad_url             0 non-null float64\n",
      "name                      26688 non-null object\n",
      "num_comments              26688 non-null float64\n",
      "original_link             0 non-null float64\n",
      "over_18                   26688 non-null bool\n",
      "permalink                 26688 non-null object\n",
      "post_hint                 3513 non-null object\n",
      "preview                   3513 non-null object\n",
      "promoted                  0 non-null float64\n",
      "promoted_by               0 non-null float64\n",
      "promoted_display_name     0 non-null float64\n",
      "promoted_url              0 non-null float64\n",
      "quarantine                26688 non-null bool\n",
      "retrieved_on              26688 non-null float64\n",
      "saved                     26688 non-null bool\n",
      "score                     26688 non-null float64\n",
      "secure_media              268 non-null object\n",
      "secure_media_embed        26688 non-null object\n",
      "selftext                  26688 non-null object\n",
      "spoiler                   26688 non-null bool\n",
      "stickied                  26688 non-null bool\n",
      "subreddit                 26688 non-null object\n",
      "subreddit_id              26688 non-null object\n",
      "third_party_tracking      0 non-null float64\n",
      "third_party_tracking_2    0 non-null float64\n",
      "thumbnail                 26688 non-null object\n",
      "title                     26688 non-null object\n",
      "ups                       26688 non-null float64\n",
      "url                       26688 non-null object\n",
      "dtypes: bool(10), float64(19), int64(1), object(23)\n",
      "memory usage: 9.0+ MB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 7.789006294964029)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the down votes column is all equal to 0 and therefore meaningless, \n",
    "# where as the up votes column many provide information\n",
    "\n",
    "reddit.downs.mean(), reddit.ups.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26688.000000\n",
       "mean         7.789006\n",
       "std        216.126418\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          2.000000\n",
       "max      26573.000000\n",
       "Name: ups, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.ups.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.63350000e+04,   1.60000000e+02,   6.40000000e+01,\n",
       "          1.80000000e+01,   2.50000000e+01,   1.40000000e+01,\n",
       "          1.30000000e+01,   5.00000000e+00,   7.00000000e+00,\n",
       "          3.00000000e+00]),\n",
       " array([   0. ,   49.5,   99. ,  148.5,  198. ,  247.5,  297. ,  346.5,\n",
       "         396. ,  445.5,  495. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD3CAYAAAAUl4NyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAED1JREFUeJzt3X+IXeWdx/H3JKMTAzdh/pgohbKi3f3iP7qSxWSJWUNr\nm+pSXAr+I911K2tVBC1baLsmoQgpbqV1MS2Ny6TZaLUgjWsXAmnyR7s2ZlFZa0GpfG1Cyy4shank\nx5TZJE2c/eOcwO3sdO7MZJKr9/t+wcC5z3nufZ7vTDife85z7s3Q9PQ0kqR6lvV7ApKk/jAAJKko\nA0CSijIAJKkoA0CSihru9wTma2Ji8oJuVxodXcmxY1NLNZ0PhIo1Q826rbmOhdY9NtYZ+kP7ypwB\nDA8v7/cULrmKNUPNuq25jqWsu0wASJJ+nwEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZ\nAJJU1AfmqyAu1Ke+8G99GXf3lz/al3ElqRfPACSpKANAkooyACSpKANAkooyACSpKANAkooyACSp\nqDk/BxARlwG7gauBEWA78N/APuAXbbedmfl8RNwL3AecBbZn5r6IuAJ4FlgDTAJ3Z+ZERKwHnmz7\nHszMR5e8MknSnHqdAXwGeDczNwKfBL4FrAWeyMxN7c/zEXEV8BCwAdgMPBYRI8ADwJvt858Btrav\n+xRwF3AzsC4iblzqwiRJc+v1SeDvA3vb7SGad+xrgYiIO2jOAj4P3AQczszTwOmIOAJcT3OAf7x9\n/n5gW0SsAkYy8yjNCx0AbgXemGsio6MrP5D/B+jYWKf0+P1SsW5rrmOp6p4zADLztwAR0aEJgq00\nl4J2ZebrEbEF+ArwM+BE11MngdXAqq727raTM/pe02uix45NzaOc95+Jicm+jT021unr+P1SsW5r\nrmOhdc8VFj0XgSPiw8CPge9m5veAFzPz9Xb3i8CNNAf07lE6wPEZ7bO1dbdLki6hOQMgIq4EDgJf\nyszdbfOBiLip3f4Y8DrwGrAxIlZExGrgOuAt4DBwe9v3NuBQZp4EzkTEtRExRLNmcGgpi5Ik9dZr\nDeARYJTm2v22tu3vgX+KiN8BvwY+l5knI2IHzYF8GbAlM09FxE7g6Yh4GThDs/ALcD/wHLCc5i6g\nV5e0KklST73WAB4GHp5l14ZZ+o4D4zPapoA7Z+n7CrB+QTOVJC0pPwgmSUUZAJJUlAEgSUUZAJJU\nlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEg\nSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZ\nAJJUlAEgSUUNz7UzIi4DdgNXAyPAduDnwB5gGngLeDAz34uIe4H7gLPA9szcFxFXAM8Ca4BJ4O7M\nnIiI9cCTbd+DmfnoRahNkjSHXmcAnwHezcyNwCeBbwFPAFvbtiHgjoi4CngI2ABsBh6LiBHgAeDN\ntu8zwNb2dZ8C7gJuBtZFxI1LW5YkqZdeAfB9YFu7PUTzjn0t8FLbth+4FbgJOJyZpzPzBHAEuJ7m\nAP/D7r4RsQoYycyjmTkNHGhfQ5J0Cc15CSgzfwsQER1gL807+K+3B25oLuusBlYBJ7qeOlt7d9vJ\nGX2v6TXR0dGVDA8v79XtfWdsrFN6/H6pWLc117FUdc8ZAAAR8WHgReDbmfm9iHi8a3cHOE5zQO/0\naO/Vd07Hjk316vK+NDEx2bexx8Y6fR2/XyrWbc11LLTuucJizktAEXElcBD4UmbubpvfiIhN7fZt\nwCHgNWBjRKyIiNXAdTQLxIeB27v7ZuZJ4ExEXBsRQzRrBofmXY0kaUn0OgN4BBgFtkXE+bWAh4Ed\nEXE58DawNzPPRcQOmgP5MmBLZp6KiJ3A0xHxMnCGZuEX4H7gOWA5zV1Ary5pVZKknnqtATxMc8Cf\n6ZZZ+o4D4zPapoA7Z+n7CrB+QTOVJC0pPwgmSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZ\nAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJU\nlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUZAJJUlAEgSUUNz6dTRKwD\nvpaZmyLiRmAf8It2987MfD4i7gXuA84C2zNzX0RcATwLrAEmgbszcyIi1gNPtn0PZuajS1uWJKmX\nnmcAEfFFYBewom1aCzyRmZvan+cj4irgIWADsBl4LCJGgAeANzNzI/AMsLV9jaeAu4CbgXVtqEiS\nLqH5XAI6Cny66/Fa4C8j4icR8Z2I6AA3AYcz83RmngCOANfTHOB/2D5vP3BrRKwCRjLzaGZOAweA\nW5eoHknSPPW8BJSZL0TE1V1NrwG7MvP1iNgCfAX4GXCiq88ksBpY1dXe3XZyRt9res1jdHQlw8PL\ne3V73xkb65Qev18q1m3NdSxV3fNaA5jhxcw8fn4b+CbwE6B7Rh3gOM2BvjNHW3f7nI4dm1rEVPtv\nYmKyb2OPjXX6On6/VKzbmutYaN1zhcVi7gI6EBE3tdsfA16nOSvYGBErImI1cB3wFnAYuL3textw\nKDNPAmci4tqIGKJZMzi0iHlIki7AYs4AHgC+GRG/A34NfC4zT0bEDpoD+TJgS2aeioidwNMR8TJw\nhmbhF+B+4DlgOc1dQK9eaCGSpIWZVwBk5q+A9e32T2nu9pnZZxwYn9E2Bdw5S99Xzr+eJKk//CCY\nJBVlAEhSUQaAJBVlAEhSUQaAJBVlAEhSUQaAJBVlAEhSUQaAJBVlAEhSUQaAJBVlAEhSUQaAJBVl\nAEhSUQaAJBVlAEhSUQaAJBVlAEhSUQaAJBVlAEhSUQaAJBVlAEhSUQaAJBVlAEhSUQaAJBVlAEhS\nUQaAJBVlAEhSUQaAJBVlAEhSUQaAJBVlAEhSUcPz6RQR64CvZeamiPgIsAeYBt4CHszM9yLiXuA+\n4CywPTP3RcQVwLPAGmASuDszJyJiPfBk2/dgZj661IVJkubW8wwgIr4I7AJWtE1PAFszcyMwBNwR\nEVcBDwEbgM3AYxExAjwAvNn2fQbY2r7GU8BdwM3Auoi4celKkiTNx3zOAI4Cnwa+2z5eC7zUbu8H\nPgGcAw5n5mngdEQcAa6nOcA/3tV3W0SsAkYy8yhARBwAbgXemGsSo6MrGR5ePt+63jfGxjqlx++X\ninVbcx1LVXfPAMjMFyLi6q6mocycbrcngdXAKuBEV5/Z2rvbTs7oe02veRw7NtWry/vSxMRk38Ye\nG+v0dfx+qVi3Ndex0LrnCovFLAK/17XdAY7THNA7Pdp79ZUkXUKLCYA3ImJTu30bcAh4DdgYESsi\nYjVwHc0C8WHg9u6+mXkSOBMR10bEEM2awaELqEGStAjzugtohi8A4xFxOfA2sDczz0XEDpoD+TJg\nS2aeioidwNMR8TJwhmbhF+B+4DlgOc1dQK9eaCGSpIWZVwBk5q+A9e32O8Ats/QZB8ZntE0Bd87S\n95XzrydJ6g8/CCZJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJ\nRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRRkA\nklSUASBJRRkAklSUASBJRRkAklSUASBJRRkAklSUASBJRQ0v9okR8VPgZPvwl8BXgT3ANPAW8GBm\nvhcR9wL3AWeB7Zm5LyKuAJ4F1gCTwN2ZObHoKiRJC7aoM4CIWAEMZeam9uezwBPA1szcCAwBd0TE\nVcBDwAZgM/BYRIwADwBvtn2fAbYuQS2SpAVY7BnADcDKiDjYvsYjwFrgpXb/fuATwDngcGaeBk5H\nxBHgeuBm4PGuvtt6DTg6upLh4eWLnG7/jI11So/fLxXrtuY6lqruxQbAFPB1YBfwxzQH8aHMnG73\nTwKrgVXAia7nzdZ+vm1Ox45NLXKq/TUxMdm3scfGOn0dv18q1m3NdSy07rnCYrEB8A5wpD3gvxMR\n79KcAZzXAY7TrBF0erSfb5MkXUKLvQvoHuAbABHxIZp39AcjYlO7/zbgEPAasDEiVkTEauA6mgXi\nw8DtM/pKki6hxZ4BfAfYExEv09z1cw/wG2A8Ii4H3gb2Zua5iNhBc4BfBmzJzFMRsRN4un3+GeCu\nCy1EkrQwiwqAzPxDB+1bZuk7DozPaJsC7lzM2JKkpeEHwSSpKANAkooyACSpKANAkooyACSpKANA\nkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooy\nACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSpKANAkooyACSp\nqOF+DRwRy4BvAzcAp4G/y8wj/ZqPJFXTzzOAvwJWZOafA18GvtHHuUhSOX07AwBuBn4IkJmvRMSf\n9XEuF809//ijfk/hktv95Y/2ewqS5mFoenq6LwNHxC7ghczc3z7+L+CazDzblwlJUjH9vAR0Euh0\nPV7mwV+SLp1+BsBh4HaAiFgPvNnHuUhSOf1cA3gR+HhE/AcwBHy2j3ORpHL6tgYgSeovPwgmSUUZ\nAJJUlAEgSUX1cxH4oqvydRMRsQ74WmZuioiPAHuAaeAt4MHMfC8i7gXuA84C2zNzX98mfAEi4jJg\nN3A1MAJsB37OANcMEBHLgXEgaOq8HzjFgNcNEBFrgNeBj9PUtIfBr/mnNLfKA/wS+CoXoe5BPwMY\n+K+biIgvAruAFW3TE8DWzNxIc3fVHRFxFfAQsAHYDDwWESP9mO8S+AzwblvfJ4FvMfg1A3wKIDM3\nAFtpDggDX3cb+P8M/G/bVKHmFcBQZm5qfz7LRap70APg975uAhjEr5s4Cny66/Fa4KV2ez9wK3AT\ncDgzT2fmCeAIcP0lneXS+T6wrd0eonnnM+g1k5k/AD7XPvwj4DgF6ga+DjwF/E/7uELNNwArI+Jg\nRPyo/ZzURal70ANgFXCi6/G5iBioy16Z+QLwu66mocw8f2/vJLCa//97ON/+gZOZv83MyYjoAHtp\n3g0PdM3nZebZiHga+CbwHANed0T8LTCRmQe6mge65tYUTfBtprnUd9H+1oMeABW/buK9ru0OzTvF\nmb+H8+0fSBHxYeDHwHcz83sUqPm8zLwb+BOa9YArunYNYt330HxY9N+BPwWeAdZ07R/EmgHeAZ7N\nzOnMfAd4F7iya/+S1T3oAVDx6ybeiIhN7fZtwCHgNWBjRKyIiNXAdTQLSR84EXElcBD4UmbubpsH\numaAiPjriPiH9uEUTej95yDXnZl/kZm3ZOYm4GfA3wD7B7nm1j2065UR8SGad/oHL0bdA3U5ZBYV\nv27iC8B4RFwOvA3szcxzEbGD5h/NMmBLZp7q5yQvwCPAKLAtIs6vBTwM7BjgmgH+FfiXiPgJcBnw\neZpaB/lvPZtB//cN8B1gT0S8THPXzz3Ab7gIdftVEJJU1KBfApIk/QEGgCQVZQBIUlEGgCQVZQBI\nUlEGgCQVZQBIUlH/B2GpWct4dVOgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119e817f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Most observations have up votes near 0, and only a few with very high scores \n",
    "# resulting in very skewed data \n",
    "\n",
    "plt.hist('ups', data=reddit[reddit.ups <= 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3699.,  15301.,   2784.,   1306.,    542.,    482.,    373.,\n",
       "           286.,    201.,    144.,    130.,    106.,     92.,     80.,\n",
       "            71.,     67.,     53.,     42.,     46.,     83.]),\n",
       " array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,\n",
       "         11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD6CAYAAACoCZCsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJBXKAJCkQhkAklQoA0CSCmUASFKh/j9K1S6gs+LzTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c5ecfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# when only looking at up votes under 20 still is very skewed. \n",
    "\n",
    "plt.hist('ups', data=reddit[reddit.ups <= 20], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26688.0\n",
       "mean         0.0\n",
       "std          0.0\n",
       "min          0.0\n",
       "25%          0.0\n",
       "50%          0.0\n",
       "75%          0.0\n",
       "max          0.0\n",
       "Name: downs, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no variation in this columns and won't be included in the final data set\n",
    "\n",
    "reddit.downs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    26678\n",
       "1.0        8\n",
       "6.0        1\n",
       "2.0        1\n",
       "Name: gilded, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is too little variation and too few observations to include in the final dataset\n",
    "\n",
    "reddit.gilded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    26688\n",
       "Name: hide_score, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no variation and won't be included\n",
    "\n",
    "reddit.hide_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    26683\n",
       "True         5\n",
       "Name: contest_mode, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not enough variation to include\n",
    "\n",
    "reddit.contest_mode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    26688\n",
       "Name: archived, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not enough variation to include\n",
    "\n",
    "reddit.archived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    26666\n",
       "True        22\n",
       "Name: locked, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not enough variation to include\n",
    "\n",
    "reddit.locked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    26688\n",
       "Name: spoiler, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no variation, will not include\n",
    "\n",
    "reddit.spoiler.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    26687\n",
       "True         1\n",
       "Name: stickied, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not enough variation to include\n",
    "\n",
    "reddit.stickied.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     24594\n",
       "False     2094\n",
       "Name: is_self, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.is_self.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "self       18192\n",
       "default     8480\n",
       "nsfw          16\n",
       "Name: thumbnail, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.thumbnail.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# too many nulls to include\n",
    "\n",
    "reddit.link_flair_css_class.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns that don't have enough variation or too many nulls in them have not been included in the new reddit df,\n",
    "# dataframe has also been reordered to show the columns of interest near the left\n",
    "# did not include link_flair_css_class because the same information is in link_flair_text\n",
    "\n",
    "reddit = reddit[['subreddit', 'ups', 'title', 'selftext', 'edited', 'is_self', 'link_flair_text', 'thumbnail']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26688 entries, 0 to 26687\n",
      "Data columns (total 8 columns):\n",
      "subreddit          26688 non-null object\n",
      "ups                26688 non-null float64\n",
      "title              26688 non-null object\n",
      "selftext           26688 non-null object\n",
      "edited             26688 non-null object\n",
      "is_self            26688 non-null bool\n",
      "link_flair_text    4610 non-null object\n",
      "thumbnail          26688 non-null object\n",
      "dtypes: bool(1), float64(1), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit.link_flair_text.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>edited</th>\n",
       "      <th>is_self</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>thumbnail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>techsupport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Help with audio set-up</td>\n",
       "      <td>I have a Sony surround sound system for a blu-...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learnprogramming</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Optimizing code for speed</td>\n",
       "      <td>I've written what seems to be a prohibitively ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gamedev</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Seeking Tales of Development Woe (and Triumph)...</td>\n",
       "      <td>I'm writing an article called \"Video Games Tha...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>learnprogramming</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[Java] Finding smallest value in an array</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1480698462</td>\n",
       "      <td>True</td>\n",
       "      <td>Solved</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>learnpython</td>\n",
       "      <td>6.0</td>\n",
       "      <td>currying functions using functools</td>\n",
       "      <td>I have the following representation of argumen...</td>\n",
       "      <td>1480709138</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit   ups                                              title  \\\n",
       "0       techsupport   1.0                             Help with audio set-up   \n",
       "1  learnprogramming  23.0                          Optimizing code for speed   \n",
       "2           gamedev  12.0  Seeking Tales of Development Woe (and Triumph)...   \n",
       "3  learnprogramming   0.0          [Java] Finding smallest value in an array   \n",
       "4       learnpython   6.0                 currying functions using functools   \n",
       "\n",
       "                                            selftext      edited  is_self  \\\n",
       "0  I have a Sony surround sound system for a blu-...       False     True   \n",
       "1  I've written what seems to be a prohibitively ...       False     True   \n",
       "2  I'm writing an article called \"Video Games Tha...       False     True   \n",
       "3                                          [deleted]  1480698462     True   \n",
       "4  I have the following representation of argumen...  1480709138     True   \n",
       "\n",
       "  link_flair_text thumbnail  \n",
       "0               0      self  \n",
       "1               0      self  \n",
       "2      Discussion      self  \n",
       "3          Solved   default  \n",
       "4               0      self  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26688, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting all observations where the text of the post has been deleted or removed. Deleted is by the user and Removed is by the website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5269, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit[reddit.selftext == '[deleted]'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3211, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit[reddit.selftext == '[removed]'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18208, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = reddit[reddit.selftext != '[deleted]']\n",
    "reddit = reddit[reddit.selftext != '[removed]']\n",
    "reddit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining y\n",
    "\n",
    "This model will use the title and text of the post to predict the subreddit it belongs to. To do this a some subreddits will be combined to broader categories. \n",
    "The remaining subreddits that have more than 1,000 observations will be included in the final dataset, and each subreddit predicted based on the words in the text of the post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[techsupport         9569\n",
       " learnprogramming    2710\n",
       " learnpython         1425\n",
       " gamedev              804\n",
       " web_design           445\n",
       " javahelp             422\n",
       " javascript           404\n",
       " csshelp              299\n",
       " Python               276\n",
       " iOSProgramming       262\n",
       " linux                227\n",
       " engineering          213\n",
       " swift                189\n",
       " computerscience      126\n",
       " django               111\n",
       " PHP                   84\n",
       " css                   77\n",
       " java                  76\n",
       " HTML                  75\n",
       " ruby                  67\n",
       " flask                 62\n",
       " compsci               43\n",
       " technology            42\n",
       " cpp                   34\n",
       " html5                 33\n",
       " pygame                32\n",
       " jquery                29\n",
       " perl                  21\n",
       " lisp                  14\n",
       " programmer             9\n",
       " dailyprogrammer        9\n",
       " IPython                8\n",
       " inventwithpython       5\n",
       " netsec                 4\n",
       " pystats                2\n",
       " Name: subreddit, dtype: int64]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reddit.subreddit.value_counts()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resets the subreddits to be more inclusive\n",
    "\n",
    "sub_list = []\n",
    "for x in reddit.subreddit:\n",
    "    if 'ython' in x or 'pygame' in x or 'pystats' in x or 'flask' in x:\n",
    "        x = 'python'\n",
    "        sub_list.append(x)\n",
    "    elif x == 'java' or x == 'javahelp':\n",
    "        x = 'java'\n",
    "        sub_list.append(x)  \n",
    "    elif 'program' in x:\n",
    "        x = 'programming'\n",
    "        sub_list.append(x)\n",
    "    elif x == 'html5':\n",
    "        x = 'HTML'\n",
    "        sub_list.append(x)\n",
    "    elif 'css' in x:\n",
    "        x =  'css'\n",
    "        sub_list.append(x)\n",
    "    else:\n",
    "        sub_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit.subreddit = sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['techsupport', 'programming', 'python']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of top subreddits\n",
    "\n",
    "sub = pd.DataFrame(reddit.subreddit.value_counts())\n",
    "\n",
    "sub = sub.loc[sub['subreddit'] >= 1000]\n",
    "sub_li = list(sub.index)\n",
    "sub_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data set now only contains observations of the subreddits with more than 1,000 instances\n",
    "\n",
    "reddit = reddit[(reddit.subreddit == 'techsupport') | (reddit.subreddit == 'programming') | \n",
    "                (reddit.subreddit == 'python')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14107, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>edited</th>\n",
       "      <th>is_self</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>thumbnail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>techsupport</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Help with audio set-up</td>\n",
       "      <td>I have a Sony surround sound system for a blu-...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>programming</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Optimizing code for speed</td>\n",
       "      <td>I've written what seems to be a prohibitively ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>6.0</td>\n",
       "      <td>currying functions using functools</td>\n",
       "      <td>I have the following representation of argumen...</td>\n",
       "      <td>1480709138</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>programming</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Text Editor integration</td>\n",
       "      <td>I am about to create a website where users use...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>python</td>\n",
       "      <td>8.0</td>\n",
       "      <td>What are some ways to learn efficient python?</td>\n",
       "      <td>This [post](https://www.reddit.com/r/learnpyth...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit   ups                                          title  \\\n",
       "0  techsupport   1.0                         Help with audio set-up   \n",
       "1  programming  23.0                      Optimizing code for speed   \n",
       "4       python   6.0             currying functions using functools   \n",
       "5  programming   1.0                        Text Editor integration   \n",
       "7       python   8.0  What are some ways to learn efficient python?   \n",
       "\n",
       "                                            selftext      edited  is_self  \\\n",
       "0  I have a Sony surround sound system for a blu-...       False     True   \n",
       "1  I've written what seems to be a prohibitively ...       False     True   \n",
       "4  I have the following representation of argumen...  1480709138     True   \n",
       "5  I am about to create a website where users use...       False     True   \n",
       "7  This [post](https://www.reddit.com/r/learnpyth...       False     True   \n",
       "\n",
       "  link_flair_text thumbnail  \n",
       "0               0      self  \n",
       "1               0      self  \n",
       "4               0      self  \n",
       "5               0      self  \n",
       "7               0      self  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binerizing Featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14107 entries, 0 to 26686\n",
      "Data columns (total 8 columns):\n",
      "subreddit          14107 non-null object\n",
      "ups                14107 non-null float64\n",
      "title              14107 non-null object\n",
      "selftext           14107 non-null object\n",
      "edited             14107 non-null object\n",
      "is_self            14107 non-null bool\n",
      "link_flair_text    14107 non-null object\n",
      "thumbnail          14107 non-null object\n",
      "dtypes: bool(1), float64(1), object(6)\n",
      "memory usage: 895.5+ KB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn boolean and object columns into binary features\n",
    "\n",
    "reddit.is_self = reddit.is_self.apply(lambda x: 0 if  x == False else 1)\n",
    "\n",
    "reddit.edited = reddit.edited.apply(lambda x: 0 if x == 'False' else 1)\n",
    "\n",
    "reddit.link_flair_text = reddit.link_flair_text.apply(lambda x: 1 if x == 'Solved' else 0)\n",
    "\n",
    "reddit.thumbnail = reddit.thumbnail.apply(lambda x: 1 if x == 'self' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14107 entries, 0 to 26686\n",
      "Data columns (total 8 columns):\n",
      "subreddit          14107 non-null object\n",
      "ups                14107 non-null float64\n",
      "title              14107 non-null object\n",
      "selftext           14107 non-null object\n",
      "edited             14107 non-null int64\n",
      "is_self            14107 non-null int64\n",
      "link_flair_text    14107 non-null int64\n",
      "thumbnail          14107 non-null int64\n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 991.9+ KB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with outliers\n",
    "\n",
    "The up votes of the posts give relevant information, however the outliers distort modeling. All votes post with 4 upvotes or more will be represented as 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit.ups = reddit.ups.apply(lambda x: x if x <= 3 else 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14107.000000\n",
       "mean         1.486850\n",
       "std          1.116251\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          2.000000\n",
       "max          4.000000\n",
       "Name: ups, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.ups.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    8611\n",
       "2.0    1744\n",
       "4.0    1637\n",
       "0.0    1339\n",
       "3.0     776\n",
       "Name: ups, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.ups.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reddit.ups = reddit.ups.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These histograms shows how the up vote distributions vary between the subreddits, and the distribution of all the up votes together (in black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEFCAYAAADt1CyEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL0mV+399fYwS0h7hQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c5facf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist('ups', data=reddit, color='black', bins=range(0,6))\n",
    "plt.title('All Subreddits Histogram of Up Votes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEFCAYAAADt1CyEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6CWpcAa9JBXOoJekwv1/EP7G99REnoQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114559978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist('ups', data=reddit[reddit.subreddit == 'techsupport'], color='indigo', bins=range(0,6))\n",
    "plt.title('Techsupport Histogram of Up Votes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEFCAYAAADt1CyEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118011978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist('ups', data=reddit[reddit.subreddit == 'programming'], color='teal', bins=range(0,6))\n",
    "plt.title('Programming Histogram of Up Votes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1190026d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist('ups', data=reddit[reddit.subreddit == 'python'], color='coral', bins=range(0,6))\n",
    "plt.title('Python Histogram of Up Votes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subreddit has a different distrubution of upvotes, but they all have a peak at 1 upvote."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each classification it dealt with separately, the model predicts if the observation is Techsupport or not, then Programming or not, and finally Python or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techsupport Classification\n",
    "\n",
    "These models predict if a post is in the subreddit Techsupport or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tech = reddit.drop('subreddit', axis=1)\n",
    "y_tech = pd.DataFrame(reddit.subreddit.apply(lambda x: 1 if x == 'techsupport' else 0))\n",
    "\n",
    "X_train_tech, X_test_tech, y_train_tech, y_test_tech = train_test_split(X_tech, y_tech, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NLP(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    '''Natural Lanugage Processing Function; separates title and text of posts processes \n",
    "    them, then joins them back together with other rows.'''\n",
    "    \n",
    "    t_vect = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "    t_vect.fit(X_train['title'])\n",
    "    X_train_t_tit = t_vect.transform(X_train['title'])\n",
    "    X_train_t_tit = pd.DataFrame(X_train_t_tit.todense())\n",
    "    X_test_t_tit = t_vect.transform(X_test['title'])\n",
    "    X_test_t_tit = pd.DataFrame(X_test_t_tit.todense())    \n",
    "\n",
    "    t_vect.fit(X_train['selftext'])\n",
    "    X_train_t_text = t_vect.transform(X_train['selftext'])\n",
    "    X_train_t_text = pd.DataFrame(X_train_t_text.todense())\n",
    "    X_test_t_text = t_vect.transform(X_test['selftext'])\n",
    "    X_test_t_text = pd.DataFrame(X_test_t_text.todense())\n",
    "    \n",
    "    # join the two NLP matrices from title and softtext columns, with the numeric columns \n",
    "    # reset inex of numeric columns for indices to match up \n",
    "\n",
    "    X_train_t = pd.concat([X_train_t_tit, X_train_t_text, X_train.drop(['title', 'selftext'], axis=1)\n",
    "                           .reset_index().drop('index', axis=1)], axis=1)\n",
    "    X_test_t = pd.concat([X_test_t_tit, X_test_t_text, X_test.drop(['title', 'selftext'], axis=1)\n",
    "                          .reset_index().drop('index', axis=1)], axis=1)\n",
    "\n",
    "    # combines and reduces features to 500, because of large amount of columns in output\n",
    "    pca = PCA(n_components=500)\n",
    "\n",
    "    X_train_t = pca.fit_transform(X_train_t)\n",
    "    X_test_t = pca.transform(X_test_t)\n",
    "    \n",
    "    # reset index of y \n",
    "    y_train = y_train.reset_index().drop('index', axis=1)\n",
    "    y_train = y_train.subreddit\n",
    "\n",
    "    y_test = y_test.reset_index().drop('index', axis=1)\n",
    "    y_test = y_test.subreddit\n",
    "    \n",
    "    return X_train_t, X_test_t, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# call the preprocessing function to get training and testing set ready for modeling\n",
    "\n",
    "X_train_tech, X_test_tech, y_train_tech, y_test_tech = NLP(X_train_tech, X_test_tech, y_train_tech, y_test_tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Models to get an idea of what models to focus on, Decision Trees, Logistic Regression, and KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.6795624873404902\n",
      "cross validated train score 0.927384710092\n",
      "cross validated test score 0.915663916503\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_tech, y_train_tech)\n",
    "\n",
    "baseline = y_train_tech.mean()\n",
    "if baseline >= 0.5:\n",
    "    print('baseline', baseline)\n",
    "else:\n",
    "    print('baseline', 1 - baseline)\n",
    "\n",
    "print('cross validated train score', cross_val_score(tree, X_train_tech, y_train_tech, cv=5).mean())\n",
    "print('cross validated test score', cross_val_score(tree, X_test_tech, y_test_tech, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.6795624873404902\n",
      "cross validated train score 0.975187154528\n",
      "cross validated test score 0.968342706245\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_tech, y_train_tech)\n",
    "\n",
    "baseline = y_train_tech.mean()\n",
    "if baseline >= 0.5:\n",
    "    print('baseline', baseline)\n",
    "else:\n",
    "    print('baseline', 1 - baseline)\n",
    "\n",
    "\n",
    "\n",
    "print('cross validated train score', cross_val_score(logreg, X_train_tech, y_train_tech, cv=5).mean())\n",
    "print('cross validated test score', cross_val_score(logreg, X_test_tech, y_test_tech, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.6795624873404902\n",
      "cross validated train score 0.846465725315\n",
      "cross validated test score 0.809361268103\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_tech, y_train_tech)\n",
    "\n",
    "baseline = y_train_tech.mean()\n",
    "if baseline >= 0.5:\n",
    "    print('baseline', baseline)\n",
    "else:\n",
    "    print('baseline', 1 - baseline)\n",
    "\n",
    "print('cross validated train score', cross_val_score(knn, X_train_tech, y_train_tech, cv=5).mean())\n",
    "print('cross validated test score', cross_val_score(knn, X_test_tech, y_test_tech, cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these preliminary results, the tunning will focus on the logistic regression and decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Function With Tunning\n",
    "\n",
    "further optimize the better models with tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forest(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    '''GridSearch on RandomForest Classifier'''\n",
    "    \n",
    "    rf = RandomForestClassifier(n_jobs=-1)\n",
    "    \n",
    "    params = {\n",
    "        'max_features':['sqrt'],\n",
    "        'n_estimators': range(10, 200),\n",
    "        'max_depth': range(20, 200)\n",
    "    }\n",
    "    \n",
    "    rand = RandomizedSearchCV(rf, param_distributions=params, verbose=3, n_jobs=-1, n_iter=20)\n",
    "    \n",
    "    rand.fit(X_train, y_train)\n",
    "    \n",
    "    print(rand.best_params_)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_jobs=-1)\n",
    "    rf.set_params(**rand.best_params_)\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    baseline = y_train.mean()\n",
    "    if baseline >= 0.5:\n",
    "        print('baseline', baseline)\n",
    "    else:\n",
    "        print('baseline', 1 - baseline)\n",
    "    \n",
    "    print ('cross val train score', cross_val_score(rf, X_train, y_train, cv=5).mean())\n",
    "    print ('cross val test score', cross_val_score(rf, X_test, y_test, cv=5).mean())\n",
    "    \n",
    "    predictions = rf.predict(X_test)\n",
    "    print (confusion_matrix(y_test, predictions))\n",
    "    print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    tree = DecisionTreeClassifier()\n",
    "    \n",
    "    params = {\n",
    "        'max_depth': range(2, 100, 5), \n",
    "        'max_features': ['auto', 'log2', None]\n",
    "    }\n",
    "    tree_rand = RandomizedSearchCV(tree, param_distributions=params, verbose=3, n_jobs=-1, cv=3)\n",
    "\n",
    "    tree_rand.fit(X_train, y_train)\n",
    "\n",
    "    print(tree_rand.best_params_)\n",
    "\n",
    "    tree = DecisionTreeClassifier(**tree_rand.best_params_)\n",
    "    tree.fit(X_train, y_train)\n",
    "    \n",
    "    baseline = y_train.mean()\n",
    "    if baseline >= 0.5:\n",
    "        print('baseline', baseline)\n",
    "    else:\n",
    "        print('baseline', 1 - baseline)\n",
    "    \n",
    "    print ('cross val train score', cross_val_score(tree, X_train, y_train, cv=5).mean())\n",
    "    print ('cross val test score',cross_val_score(tree, X_test, y_test, cv=5).mean())\n",
    "    \n",
    "    predictions = tree.predict(X_test)\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This gridsearch isn't able to run because of time issues, so the same optimization is done belwo manually\n",
    "\n",
    "# def logistic(X_train, X_test, y_train, y_test):\n",
    "#     logreg = LogisticRegression()\n",
    "    \n",
    "#     params = {'C': [1, 10, 100, 1000]}\n",
    "    \n",
    "#     grid = GridSearchCV(logreg, param_grid=params, verbose=3, n_jobs=-1, cv=2)\n",
    "    \n",
    "#     grid.fit(X_train, y_train)\n",
    "    \n",
    "#     print(grid.best_params_)\n",
    "    \n",
    "#     logreg = LogisticRegression()\n",
    "#     logreg.set_params(**grid.best_params_)\n",
    "    \n",
    "#     logreg.fit(X_train, y_train)\n",
    "\n",
    "#     baseline = y_train.mean()\n",
    "#     if baseline >= 0.5:\n",
    "#         print('baseline', baseline)\n",
    "#     else:\n",
    "#         print('baseline', 1 - baseline)\n",
    "    \n",
    "#     print ('cross val train score', cross_val_score(logreg, X_train, y_train, cv=5).mean())\n",
    "#     print ('cross val test score', cross_val_score(logreg, X_test, y_test, cv=5).mean())\n",
    "    \n",
    "#     predictions = logreg.predict(X_test)\n",
    "#     print (confusion_matrix(y_test, predictions))\n",
    "#     print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "to tun the parameters of the logistic regression, gridsearch is not able to work effectively. So the parameters are tunned via a function below. The parameters are given the default values of the high cross val test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log(X_train, X_test, y_train, y_test, C=1):\n",
    "    logreg = LogisticRegression(C=C)\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    baseline = y_train.mean()\n",
    "    if baseline >= 0.5:\n",
    "        print('baseline', baseline)\n",
    "    else:\n",
    "        print('baseline', 1 - baseline)\n",
    "\n",
    "    print('cross validated train score', cross_val_score(logreg, X_train, y_train, cv=5).mean())\n",
    "    print('cross validated test score', cross_val_score(logreg, X_test, y_test, cv=5).mean())\n",
    "    \n",
    "    predictions = logreg.predict(X_test)\n",
    "    print (confusion_matrix(y_test, predictions))\n",
    "    print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.6795624873404902\n",
      "cross validated train score 0.974984674182\n",
      "cross validated test score 0.968107137618\n",
      "[[1309   65]\n",
      " [  45 2814]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96      1374\n",
      "          1       0.98      0.98      0.98      2859\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4233\n",
      "\n",
      "CPU times: user 4.82 s, sys: 225 ms, total: 5.05 s\n",
      "Wall time: 5.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log(X_train_tech, X_test_tech, y_train_tech, y_test_tech, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.6795624873404902\n",
      "cross validated train score 0.9741744963\n",
      "cross validated test score 0.968106019854\n",
      "[[1316   58]\n",
      " [  55 2804]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96      1374\n",
      "          1       0.98      0.98      0.98      2859\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4233\n",
      "\n",
      "CPU times: user 6.78 s, sys: 239 ms, total: 7.01 s\n",
      "Wall time: 7.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log(X_train_tech, X_test_tech, y_train_tech, y_test_tech, C=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.6795624873404902\n",
      "cross validated train score 0.973769330409\n",
      "cross validated test score 0.966924823428\n",
      "[[1314   60]\n",
      " [  58 2801]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.96      0.96      1374\n",
      "          1       0.98      0.98      0.98      2859\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4233\n",
      "\n",
      "CPU times: user 6.74 s, sys: 225 ms, total: 6.97 s\n",
      "Wall time: 6.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log(X_train_tech, X_test_tech, y_train_tech, y_test_tech, C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.6795624873404902\n",
      "cross validated train score 0.961109409667\n",
      "cross validated test score 0.954637809743\n",
      "[[1294   80]\n",
      " [  66 2793]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.94      0.95      1374\n",
      "          1       0.97      0.98      0.97      2859\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4233\n",
      "\n",
      "CPU times: user 18 s, sys: 419 ms, total: 18.4 s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log(X_train_tech, X_test_tech, y_train_tech, y_test_tech, C=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest cross val score on the test data so far is the logist regression with a C=1, when the other parameters are altered there is not effect of the score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the randomsearch functions on randomforest and decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "forest_grid(X_train_tech, X_test_tech, y_train_tech, y_test_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tree(X_train_tech, X_test_tech, y_train_tech, y_test_tech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Techsupport\n",
    "\n",
    "The best model by far is the Logistic Regression model so this will be used to predict the subreddits programming and python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pro = reddit.drop('subreddit', axis=1)\n",
    "y_pro = pd.DataFrame(reddit.subreddit.apply(lambda x: 1 if x == 'programming' else 0))\n",
    "\n",
    "X_train_pro, X_test_pro, y_train_pro, y_test_pro = train_test_split(X_pro, y_pro, test_size=.3, random_state=42)\n",
    "\n",
    "# call preprocessing NLP function\n",
    "\n",
    "X_train_pro, X_test_pro, y_train_pro, y_test_pro = NLP(X_train_pro, X_test_pro, y_train_pro, y_test_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8061575855782864\n",
      "cross validated train score 0.921915432265\n",
      "cross validated test score 0.914957769503\n",
      "[[3280  139]\n",
      " [ 192  622]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95      3419\n",
      "          1       0.82      0.76      0.79       814\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log(X_train_pro, X_test_pro, y_train_pro, y_test_pro, C=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8061575855782864\n",
      "cross validated train score 0.921915175766\n",
      "cross validated test score 0.910470787953\n",
      "[[3280  139]\n",
      " [ 189  625]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.95      3419\n",
      "          1       0.82      0.77      0.79       814\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log(X_train_pro, X_test_pro, y_train_pro, y_test_pro, C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8061575855782864\n",
      "cross validated train score 0.916648942583\n",
      "cross validated test score 0.893934596872\n",
      "[[3266  153]\n",
      " [ 181  633]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.95      3419\n",
      "          1       0.81      0.78      0.79       814\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log(X_train_pro, X_test_pro, y_train_pro, y_test_pro, C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8061575855782864\n",
      "cross validated train score 0.914623472228\n",
      "cross validated test score 0.877391140328\n",
      "[[3261  158]\n",
      " [ 181  633]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95      3419\n",
      "          1       0.80      0.78      0.79       814\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log(X_train_pro, X_test_pro, y_train_pro, y_test_pro, C=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for the purposes of being complete, the programming classification will also go through the other model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_grid(X_train_pro, X_test_pro, y_train_pro, y_test_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree(X_train_pro, X_test_pro, y_train_pro, y_test_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The model the procissed the best results in the logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_py = reddit.drop('subreddit', axis=1)\n",
    "y_py = pd.DataFrame(reddit.subreddit.apply(lambda x: 1 if x == 'python' else 0))\n",
    "\n",
    "X_train_py, X_test_py, y_train_py, y_test_py = train_test_split(X_py, y_py, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call preprocessing NLP function\n",
    "\n",
    "X_train_py, X_test_py, y_train_py, y_test_py = NLP(X_train_py, X_test_py, y_train_py, y_test_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8734049017622038\n",
      "cross validated train score 0.936398650815\n",
      "cross validated test score 0.921097406784\n",
      "[[3605   68]\n",
      " [ 217  343]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96      3673\n",
      "          1       0.83      0.61      0.71       560\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log(X_train_py, X_test_py, y_train_py, y_test_py, C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8734049017622038\n",
      "cross validated train score 0.936802995909\n",
      "cross validated test score 0.928657673725\n",
      "[[3588   85]\n",
      " [ 191  369]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96      3673\n",
      "          1       0.81      0.66      0.73       560\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log(X_train_py, X_test_py, y_train_py, y_test_py, C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8734049017622038\n",
      "cross validated train score 0.93234642761\n",
      "cross validated test score 0.91684459963\n",
      "[[3572  101]\n",
      " [ 178  382]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96      3673\n",
      "          1       0.79      0.68      0.73       560\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log(X_train_py, X_test_py, y_train_py, y_test_py, C=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8734049017622038\n",
      "cross validated train score 0.929206776705\n",
      "cross validated test score 0.896530376995\n",
      "[[3572  101]\n",
      " [ 179  381]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96      3673\n",
      "          1       0.79      0.68      0.73       560\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log(X_train_py, X_test_py, y_train_py, y_test_py, C=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for the purposes of being complete, the programming classification will also go through the other model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_grid(X_train_py, X_test_py, y_train_py, y_test_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree(X_train_py, X_test_py, y_train_py, y_test_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The best model turned out to be the logistic regression with parameter C = 8. \n",
    "It preformed better than the KNN classifier and the Decision Tree, and Randomforest, both when they were optimized with grid search. Every model preformed much higher than the Baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy score on the test data from the Logistic Regression for predicting \n",
    "- 0.9681 Techsupport \n",
    "- 0.9149 Programming\n",
    "- 0.9286 Python      \n",
    "\n",
    "All these scores are above the base line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Bonus - Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people, load_boston, load_breast_cancer, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I create simple neural networks to the classify the data in the same way. The first is where the subreddit is Techsupport or not.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techsupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9874 samples, validate on 4233 samples\n",
      "Epoch 1/25\n",
      "9874/9874 [==============================] - 4s 362us/step - loss: 0.1982 - acc: 0.9163 - val_loss: 0.0822 - val_acc: 0.9717\n",
      "Epoch 2/25\n",
      "9874/9874 [==============================] - 3s 279us/step - loss: 0.0533 - acc: 0.9828 - val_loss: 0.1002 - val_acc: 0.9665\n",
      "Epoch 3/25\n",
      "9874/9874 [==============================] - 3s 285us/step - loss: 0.0350 - acc: 0.9887 - val_loss: 0.1041 - val_acc: 0.9681\n",
      "Epoch 4/25\n",
      "9874/9874 [==============================] - 3s 315us/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.1178 - val_acc: 0.9662\n",
      "Epoch 5/25\n",
      "9874/9874 [==============================] - 3s 306us/step - loss: 0.0186 - acc: 0.9942 - val_loss: 0.1233 - val_acc: 0.9698\n",
      "Epoch 6/25\n",
      "9874/9874 [==============================] - 3s 303us/step - loss: 0.0106 - acc: 0.9968 - val_loss: 0.1378 - val_acc: 0.9688\n",
      "Epoch 7/25\n",
      "9874/9874 [==============================] - 3s 311us/step - loss: 0.0125 - acc: 0.9948 - val_loss: 0.1458 - val_acc: 0.9683\n",
      "Epoch 8/25\n",
      "9874/9874 [==============================] - 3s 297us/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.1431 - val_acc: 0.9705\n",
      "Epoch 9/25\n",
      "9874/9874 [==============================] - 3s 305us/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.1713 - val_acc: 0.9676\n",
      "Epoch 10/25\n",
      "9874/9874 [==============================] - 3s 294us/step - loss: 0.0026 - acc: 0.9989 - val_loss: 0.2191 - val_acc: 0.9665\n",
      "Epoch 11/25\n",
      "9874/9874 [==============================] - 3s 312us/step - loss: 0.0108 - acc: 0.9978 - val_loss: 0.1614 - val_acc: 0.9643\n",
      "Epoch 12/25\n",
      "9874/9874 [==============================] - 3s 280us/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.1424 - val_acc: 0.9693\n",
      "Epoch 13/25\n",
      "9874/9874 [==============================] - 3s 285us/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.1585 - val_acc: 0.9698\n",
      "Epoch 14/25\n",
      "9874/9874 [==============================] - 3s 301us/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.1695 - val_acc: 0.9698\n",
      "Epoch 15/25\n",
      "9874/9874 [==============================] - 3s 335us/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.1588 - val_acc: 0.9669\n",
      "Epoch 16/25\n",
      "9874/9874 [==============================] - 3s 303us/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.1766 - val_acc: 0.9676\n",
      "Epoch 17/25\n",
      "9874/9874 [==============================] - 3s 304us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.1988 - val_acc: 0.9686\n",
      "Epoch 18/25\n",
      "9874/9874 [==============================] - 3s 286us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.2090 - val_acc: 0.9683\n",
      "Epoch 19/25\n",
      "9874/9874 [==============================] - 3s 312us/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.2014 - val_acc: 0.9669\n",
      "Epoch 20/25\n",
      "9874/9874 [==============================] - 3s 302us/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.1812 - val_acc: 0.9655\n",
      "Epoch 21/25\n",
      "9874/9874 [==============================] - 3s 294us/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.2224 - val_acc: 0.9615\n",
      "Epoch 22/25\n",
      "9874/9874 [==============================] - 3s 287us/step - loss: 0.0069 - acc: 0.9976 - val_loss: 0.1758 - val_acc: 0.9681\n",
      "Epoch 23/25\n",
      "9874/9874 [==============================] - 3s 306us/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.1877 - val_acc: 0.9672\n",
      "Epoch 24/25\n",
      "9874/9874 [==============================] - 3s 285us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2050 - val_acc: 0.9695\n",
      "Epoch 25/25\n",
      "9874/9874 [==============================] - 3s 305us/step - loss: 9.7509e-05 - acc: 1.0000 - val_loss: 0.2232 - val_acc: 0.9695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1236df5c0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reddit.drop('subreddit', axis=1)\n",
    "y = reddit.subreddit.apply(lambda x: 1 if x == 'techsupport' else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = NLP(X_train, X_test, y_train, y_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.969525159461\n",
      "[[1309   65]\n",
      " [  64 2795]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95      1374\n",
      "          1       0.98      0.98      0.98      2859\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred_tech = []\n",
    "for x in pred:\n",
    "    if x <= .5:\n",
    "        x = 0\n",
    "        pred_tech.append(x)\n",
    "    else:\n",
    "        x = 1\n",
    "        pred_tech.append(x)\n",
    "\n",
    "print('accuracy score', accuracy_score(y_test, pred_tech))        \n",
    "        \n",
    "print (confusion_matrix(y_test, pred_tech))\n",
    "\n",
    "print (classification_report(y_test, pred_tech))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score is a slight improvement from the Logstics Regression. \n",
    "Logistic Regression was 0.9681 compared to 0.9695 for the Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9874 samples, validate on 4233 samples\n",
      "Epoch 1/25\n",
      "9874/9874 [==============================] - 4s 366us/step - loss: 0.2806 - acc: 0.8804 - val_loss: 0.1898 - val_acc: 0.9180\n",
      "Epoch 2/25\n",
      "9874/9874 [==============================] - 3s 324us/step - loss: 0.1421 - acc: 0.9435 - val_loss: 0.1835 - val_acc: 0.9218\n",
      "Epoch 3/25\n",
      "9874/9874 [==============================] - 3s 313us/step - loss: 0.1049 - acc: 0.9593 - val_loss: 0.1941 - val_acc: 0.9187\n",
      "Epoch 4/25\n",
      "9874/9874 [==============================] - 3s 298us/step - loss: 0.0758 - acc: 0.9689 - val_loss: 0.2310 - val_acc: 0.9206\n",
      "Epoch 5/25\n",
      "9874/9874 [==============================] - 3s 303us/step - loss: 0.0537 - acc: 0.9791 - val_loss: 0.2775 - val_acc: 0.9173\n",
      "Epoch 6/25\n",
      "9874/9874 [==============================] - 3s 313us/step - loss: 0.0386 - acc: 0.9858 - val_loss: 0.2906 - val_acc: 0.9161\n",
      "Epoch 7/25\n",
      "9874/9874 [==============================] - 3s 312us/step - loss: 0.0284 - acc: 0.9897 - val_loss: 0.3236 - val_acc: 0.9164\n",
      "Epoch 8/25\n",
      "9874/9874 [==============================] - 3s 300us/step - loss: 0.0223 - acc: 0.9931 - val_loss: 0.3751 - val_acc: 0.9116\n",
      "Epoch 9/25\n",
      "9874/9874 [==============================] - 3s 316us/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.4074 - val_acc: 0.9180\n",
      "Epoch 10/25\n",
      "9874/9874 [==============================] - 3s 307us/step - loss: 0.0164 - acc: 0.9952 - val_loss: 0.4085 - val_acc: 0.9100\n",
      "Epoch 11/25\n",
      "9874/9874 [==============================] - 3s 343us/step - loss: 0.0144 - acc: 0.9954 - val_loss: 0.4439 - val_acc: 0.9166\n",
      "Epoch 12/25\n",
      "9874/9874 [==============================] - 4s 369us/step - loss: 0.0135 - acc: 0.9952 - val_loss: 0.4009 - val_acc: 0.9161\n",
      "Epoch 13/25\n",
      "9874/9874 [==============================] - 4s 363us/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.4612 - val_acc: 0.9206\n",
      "Epoch 14/25\n",
      "9874/9874 [==============================] - 4s 366us/step - loss: 0.0080 - acc: 0.9972 - val_loss: 0.4824 - val_acc: 0.9197\n",
      "Epoch 15/25\n",
      "9874/9874 [==============================] - 4s 362us/step - loss: 0.0162 - acc: 0.9956 - val_loss: 0.4165 - val_acc: 0.9185\n",
      "Epoch 16/25\n",
      "9874/9874 [==============================] - 3s 330us/step - loss: 0.0132 - acc: 0.9954 - val_loss: 0.4381 - val_acc: 0.9164\n",
      "Epoch 17/25\n",
      "9874/9874 [==============================] - 3s 312us/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.4834 - val_acc: 0.9192\n",
      "Epoch 18/25\n",
      "9874/9874 [==============================] - 3s 339us/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.5083 - val_acc: 0.9180\n",
      "Epoch 19/25\n",
      "9874/9874 [==============================] - 4s 357us/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.5258 - val_acc: 0.9204\n",
      "Epoch 20/25\n",
      "9874/9874 [==============================] - 4s 366us/step - loss: 0.0042 - acc: 0.9984 - val_loss: 0.5650 - val_acc: 0.9140\n",
      "Epoch 21/25\n",
      "9874/9874 [==============================] - 4s 372us/step - loss: 0.0150 - acc: 0.9953 - val_loss: 0.4016 - val_acc: 0.9190\n",
      "Epoch 22/25\n",
      "9874/9874 [==============================] - 4s 371us/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.4726 - val_acc: 0.9176\n",
      "Epoch 23/25\n",
      "9874/9874 [==============================] - 4s 360us/step - loss: 0.0035 - acc: 0.9985 - val_loss: 0.5555 - val_acc: 0.9176\n",
      "Epoch 24/25\n",
      "9874/9874 [==============================] - 4s 358us/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.5445 - val_acc: 0.9185\n",
      "Epoch 25/25\n",
      "9874/9874 [==============================] - 4s 361us/step - loss: 0.0137 - acc: 0.9950 - val_loss: 0.4515 - val_acc: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b8c08d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reddit.drop('subreddit', axis=1)\n",
    "y = reddit.subreddit.apply(lambda x: 1 if x == 'programming' else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = NLP(X_train, X_test, y_train, y_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.918025041342\n",
      "[[3267  152]\n",
      " [ 195  619]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95      3419\n",
      "          1       0.80      0.76      0.78       814\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred_pro = []\n",
    "for x in pred:\n",
    "    if x <= .5:\n",
    "        x = 0\n",
    "        pred_pro.append(x)\n",
    "    else:\n",
    "        x = 1\n",
    "        pred_pro.append(x)\n",
    "\n",
    "print('accuracy score', accuracy_score(y_test, pred_pro))        \n",
    "        \n",
    "print (confusion_matrix(y_test, pred_pro))\n",
    "\n",
    "print (classification_report(y_test, pred_pro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score for this neural network almost identical to the score of Logistic regression. Logistic Regression was 0.9149 compared to 0.9180 for the nueral network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9874 samples, validate on 4233 samples\n",
      "Epoch 1/25\n",
      "9874/9874 [==============================] - 4s 375us/step - loss: 0.2069 - acc: 0.9175 - val_loss: 0.1644 - val_acc: 0.9279\n",
      "Epoch 2/25\n",
      "9874/9874 [==============================] - 3s 320us/step - loss: 0.1129 - acc: 0.9548 - val_loss: 0.1495 - val_acc: 0.9343\n",
      "Epoch 3/25\n",
      "9874/9874 [==============================] - 3s 301us/step - loss: 0.0840 - acc: 0.9659 - val_loss: 0.1584 - val_acc: 0.9360\n",
      "Epoch 4/25\n",
      "9874/9874 [==============================] - 3s 319us/step - loss: 0.0605 - acc: 0.9759 - val_loss: 0.1925 - val_acc: 0.9372\n",
      "Epoch 5/25\n",
      "9874/9874 [==============================] - 3s 304us/step - loss: 0.0420 - acc: 0.9839 - val_loss: 0.2245 - val_acc: 0.9317\n",
      "Epoch 6/25\n",
      "9874/9874 [==============================] - 3s 326us/step - loss: 0.0278 - acc: 0.9902 - val_loss: 0.2888 - val_acc: 0.9324\n",
      "Epoch 7/25\n",
      "9874/9874 [==============================] - 3s 336us/step - loss: 0.0194 - acc: 0.9943 - val_loss: 0.3080 - val_acc: 0.9350\n",
      "Epoch 8/25\n",
      "9874/9874 [==============================] - 3s 288us/step - loss: 0.0198 - acc: 0.9936 - val_loss: 0.3392 - val_acc: 0.9327\n",
      "Epoch 9/25\n",
      "9874/9874 [==============================] - 3s 277us/step - loss: 0.0171 - acc: 0.9946 - val_loss: 0.3442 - val_acc: 0.9282\n",
      "Epoch 10/25\n",
      "9874/9874 [==============================] - 3s 302us/step - loss: 0.0123 - acc: 0.9965 - val_loss: 0.3497 - val_acc: 0.9301\n",
      "Epoch 11/25\n",
      "9874/9874 [==============================] - 3s 306us/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.3833 - val_acc: 0.9310\n",
      "Epoch 12/25\n",
      "9874/9874 [==============================] - 3s 301us/step - loss: 0.0075 - acc: 0.9982 - val_loss: 0.3817 - val_acc: 0.9334\n",
      "Epoch 13/25\n",
      "9874/9874 [==============================] - 3s 301us/step - loss: 0.0093 - acc: 0.9971 - val_loss: 0.3544 - val_acc: 0.9324\n",
      "Epoch 14/25\n",
      "9874/9874 [==============================] - 3s 330us/step - loss: 0.0107 - acc: 0.9971 - val_loss: 0.3710 - val_acc: 0.9322\n",
      "Epoch 15/25\n",
      "9874/9874 [==============================] - 3s 312us/step - loss: 0.0116 - acc: 0.9970 - val_loss: 0.3444 - val_acc: 0.9327\n",
      "Epoch 16/25\n",
      "9874/9874 [==============================] - 3s 299us/step - loss: 0.0088 - acc: 0.9977 - val_loss: 0.3776 - val_acc: 0.9310\n",
      "Epoch 17/25\n",
      "9874/9874 [==============================] - 3s 316us/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.4093 - val_acc: 0.9360\n",
      "Epoch 18/25\n",
      "9874/9874 [==============================] - 3s 299us/step - loss: 0.0044 - acc: 0.9993 - val_loss: 0.4605 - val_acc: 0.9279\n",
      "Epoch 19/25\n",
      "9874/9874 [==============================] - 3s 311us/step - loss: 0.0084 - acc: 0.9983 - val_loss: 0.4296 - val_acc: 0.9305\n",
      "Epoch 20/25\n",
      "9874/9874 [==============================] - 3s 316us/step - loss: 0.0100 - acc: 0.9972 - val_loss: 0.3963 - val_acc: 0.9272\n",
      "Epoch 21/25\n",
      "9874/9874 [==============================] - 3s 306us/step - loss: 0.0107 - acc: 0.9968 - val_loss: 0.3912 - val_acc: 0.9362\n",
      "Epoch 22/25\n",
      "9874/9874 [==============================] - 3s 284us/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.3550 - val_acc: 0.9301\n",
      "Epoch 23/25\n",
      "9874/9874 [==============================] - 3s 302us/step - loss: 0.0057 - acc: 0.9988 - val_loss: 0.3816 - val_acc: 0.9327\n",
      "Epoch 24/25\n",
      "9874/9874 [==============================] - 3s 307us/step - loss: 0.0033 - acc: 0.9994 - val_loss: 0.4354 - val_acc: 0.9331\n",
      "Epoch 25/25\n",
      "9874/9874 [==============================] - 3s 310us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.4842 - val_acc: 0.9339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120066198>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reddit.drop('subreddit', axis=1)\n",
    "y = reddit.subreddit.apply(lambda x: 1 if x == 'python' else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test = NLP(X_train, X_test, y_train, y_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.933853059296\n",
      "[[3545  128]\n",
      " [ 152  408]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.96      3673\n",
      "          1       0.76      0.73      0.74       560\n",
      "\n",
      "avg / total       0.93      0.93      0.93      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred_py = []\n",
    "for x in pred:\n",
    "    if x <= .5:\n",
    "        x = 0\n",
    "        pred_py.append(x)\n",
    "    else:\n",
    "        x = 1\n",
    "        pred_py.append(x)\n",
    "\n",
    "print('accuracy score', accuracy_score(y_test, pred_py))        \n",
    "        \n",
    "print (confusion_matrix(y_test, pred_py))\n",
    "\n",
    "print (classification_report(y_test, pred_py))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting if the subreddit was in the python category had the biggest difference in using a logistic regression model and the neural network. The Logistic Regression Score was 0.9286 and the neural network improved that score to 0.9338. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network predicting all three classes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9874, 500), (9874, 3))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reddit.drop('subreddit', axis=1)\n",
    "y = pd.DataFrame(reddit.subreddit.apply(lambda x: 2 if x == 'techsupport' else (1 if x =='programming' else 0)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "X_train, X_test, y_train, y_test_ = NLP(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test_)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9874 samples, validate on 4233 samples\n",
      "Epoch 1/30\n",
      "9874/9874 [==============================] - 2s 187us/step - loss: 0.5899 - acc: 0.7498 - val_loss: 0.2718 - val_acc: 0.8868\n",
      "Epoch 2/30\n",
      "9874/9874 [==============================] - 1s 120us/step - loss: 0.2333 - acc: 0.9031 - val_loss: 0.2054 - val_acc: 0.9194\n",
      "Epoch 3/30\n",
      "9874/9874 [==============================] - 1s 120us/step - loss: 0.1782 - acc: 0.9307 - val_loss: 0.1960 - val_acc: 0.9223\n",
      "Epoch 4/30\n",
      "9874/9874 [==============================] - 1s 122us/step - loss: 0.1560 - acc: 0.9375 - val_loss: 0.1991 - val_acc: 0.9235\n",
      "Epoch 5/30\n",
      "9874/9874 [==============================] - 1s 124us/step - loss: 0.1426 - acc: 0.9455 - val_loss: 0.1992 - val_acc: 0.9206\n",
      "Epoch 6/30\n",
      "9874/9874 [==============================] - 1s 120us/step - loss: 0.1236 - acc: 0.9519 - val_loss: 0.1995 - val_acc: 0.9242\n",
      "Epoch 7/30\n",
      "9874/9874 [==============================] - 1s 134us/step - loss: 0.1157 - acc: 0.9555 - val_loss: 0.2113 - val_acc: 0.9190\n",
      "Epoch 8/30\n",
      "9874/9874 [==============================] - 1s 131us/step - loss: 0.1033 - acc: 0.9591 - val_loss: 0.2134 - val_acc: 0.9230\n",
      "Epoch 9/30\n",
      "9874/9874 [==============================] - 1s 129us/step - loss: 0.0954 - acc: 0.9635 - val_loss: 0.2176 - val_acc: 0.9244\n",
      "Epoch 10/30\n",
      "9874/9874 [==============================] - 1s 120us/step - loss: 0.0836 - acc: 0.9695 - val_loss: 0.2333 - val_acc: 0.9206\n",
      "Epoch 11/30\n",
      "9874/9874 [==============================] - 1s 134us/step - loss: 0.0750 - acc: 0.9708 - val_loss: 0.2460 - val_acc: 0.9192\n",
      "Epoch 12/30\n",
      "9874/9874 [==============================] - 1s 132us/step - loss: 0.0695 - acc: 0.9740 - val_loss: 0.2488 - val_acc: 0.9183\n",
      "Epoch 13/30\n",
      "9874/9874 [==============================] - 2s 152us/step - loss: 0.0634 - acc: 0.9768 - val_loss: 0.2527 - val_acc: 0.9218\n",
      "Epoch 14/30\n",
      "9874/9874 [==============================] - 1s 131us/step - loss: 0.0598 - acc: 0.9781 - val_loss: 0.2588 - val_acc: 0.9206\n",
      "Epoch 15/30\n",
      "9874/9874 [==============================] - 1s 140us/step - loss: 0.0518 - acc: 0.9826 - val_loss: 0.2800 - val_acc: 0.9187\n",
      "Epoch 16/30\n",
      "9874/9874 [==============================] - 1s 135us/step - loss: 0.0519 - acc: 0.9816 - val_loss: 0.2795 - val_acc: 0.9194\n",
      "Epoch 17/30\n",
      "9874/9874 [==============================] - 1s 124us/step - loss: 0.0473 - acc: 0.9848 - val_loss: 0.2778 - val_acc: 0.9202\n",
      "Epoch 18/30\n",
      "9874/9874 [==============================] - 1s 125us/step - loss: 0.0379 - acc: 0.9871 - val_loss: 0.2928 - val_acc: 0.9227\n",
      "Epoch 19/30\n",
      "9874/9874 [==============================] - 1s 129us/step - loss: 0.0380 - acc: 0.9855 - val_loss: 0.3129 - val_acc: 0.9190\n",
      "Epoch 20/30\n",
      "9874/9874 [==============================] - 1s 126us/step - loss: 0.0375 - acc: 0.9872 - val_loss: 0.3067 - val_acc: 0.9239\n",
      "Epoch 21/30\n",
      "9874/9874 [==============================] - 1s 124us/step - loss: 0.0369 - acc: 0.9862 - val_loss: 0.3198 - val_acc: 0.9202\n",
      "Epoch 22/30\n",
      "9874/9874 [==============================] - 1s 118us/step - loss: 0.0298 - acc: 0.9896 - val_loss: 0.3405 - val_acc: 0.9168\n",
      "Epoch 23/30\n",
      "9874/9874 [==============================] - 1s 119us/step - loss: 0.0312 - acc: 0.9887 - val_loss: 0.3430 - val_acc: 0.9194\n",
      "Epoch 24/30\n",
      "9874/9874 [==============================] - 1s 118us/step - loss: 0.0325 - acc: 0.9861 - val_loss: 0.3386 - val_acc: 0.9192\n",
      "Epoch 25/30\n",
      "9874/9874 [==============================] - 1s 127us/step - loss: 0.0311 - acc: 0.9884 - val_loss: 0.3461 - val_acc: 0.9190\n",
      "Epoch 26/30\n",
      "9874/9874 [==============================] - 1s 126us/step - loss: 0.0300 - acc: 0.9892 - val_loss: 0.3530 - val_acc: 0.9194\n",
      "Epoch 27/30\n",
      "9874/9874 [==============================] - 1s 122us/step - loss: 0.0267 - acc: 0.9912 - val_loss: 0.3769 - val_acc: 0.9171\n",
      "Epoch 28/30\n",
      "9874/9874 [==============================] - 1s 150us/step - loss: 0.0275 - acc: 0.9907 - val_loss: 0.3732 - val_acc: 0.9171\n",
      "Epoch 29/30\n",
      "9874/9874 [==============================] - 1s 147us/step - loss: 0.0250 - acc: 0.9916 - val_loss: 0.3857 - val_acc: 0.9190\n",
      "Epoch 30/30\n",
      "9874/9874 [==============================] - 1s 130us/step - loss: 0.0247 - acc: 0.9915 - val_loss: 0.4081 - val_acc: 0.9168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ce72f60>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_tot = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_ = np.array(y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score 0.916843845972\n",
      "[[ 376  170   14]\n",
      " [  67  701   46]\n",
      " [   7   48 2804]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.67      0.74       560\n",
      "          1       0.76      0.86      0.81       814\n",
      "          2       0.98      0.98      0.98      2859\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score', accuracy_score(y_test_, pred_tot))        \n",
    "        \n",
    "print (confusion_matrix(y_test_, pred_tot))\n",
    "\n",
    "print (classification_report(y_test_, pred_tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general the neural networks improved on the logistic regression, but not by a significant amount."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
